diskcache
scipy
numpy
pillow
gguf

# for Windows
llama-cpp-python @ https://github.com/JamePeng/llama-cpp-python/releases/download/v0.3.18-cu126-AVX2-win-20251220/llama_cpp_python-0.3.18-cp310-cp310-win_amd64.whl; python_version == "3.10" and platform_system == "Windows"
llama-cpp-python @ https://github.com/JamePeng/llama-cpp-python/releases/download/v0.3.18-cu126-AVX2-win-20251220/llama_cpp_python-0.3.18-cp311-cp311-win_amd64.whl; python_version == "3.11" and platform_system == "Windows"
llama-cpp-python @ https://github.com/JamePeng/llama-cpp-python/releases/download/v0.3.18-cu126-AVX2-win-20251220/llama_cpp_python-0.3.18-cp312-cp312-win_amd64.whl; python_version == "3.12" and platform_system == "Windows"
llama-cpp-python @ https://github.com/JamePeng/llama-cpp-python/releases/download/v0.3.18-cu126-AVX2-win-20251220/llama_cpp_python-0.3.18-cp313-cp313-win_amd64.whl; python_version == "3.13" and platform_system == "Windows"

# for Linux
llama-cpp-python @ https://github.com/JamePeng/llama-cpp-python/releases/download/v0.3.18-cu126-AVX2-win-20251220/llama_cpp_python-0.3.18-cp310-cp310-linux_amd64.whl; python_version == "3.10" and platform_system == "Linux"
llama-cpp-python @ https://github.com/JamePeng/llama-cpp-python/releases/download/v0.3.18-cu126-AVX2-win-20251220/llama_cpp_python-0.3.18-cp311-cp311-linux_amd64.whl; python_version == "3.11" and platform_system == "Linux"
llama-cpp-python @ https://github.com/JamePeng/llama-cpp-python/releases/download/v0.3.18-cu126-AVX2-win-20251220/llama_cpp_python-0.3.18-cp312-cp312-linux_amd64.whl; python_version == "3.12" and platform_system == "Linux"
llama-cpp-python @ https://github.com/JamePeng/llama-cpp-python/releases/download/v0.3.18-cu126-AVX2-win-20251220/llama_cpp_python-0.3.18-cp313-cp313-linux_amd64.whl; python_version == "3.13" and platform_system == "Linux"